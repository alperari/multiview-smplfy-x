{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980a2931",
   "metadata": {},
   "source": [
    "# MultiviewSMPLifyX Inference Notebook\n",
    "\n",
    "This notebook is a cell-by-cell version of `main.py` for interactive inference.\n",
    "\n",
    "Current scope:\n",
    "- Load config and dataset\n",
    "- Build SMPL model + priors\n",
    "- Build multiview cameras and keypoints\n",
    "- Run fitting and export mesh/params\n",
    "\n",
    "Later we can add overlay visualization cells for projected mesh on input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import smplx\n",
    "\n",
    "from utils import JointMapper\n",
    "from cmd_parser import parse_config\n",
    "from data_parser import create_dataset\n",
    "from fit_single_frame import fit_single_frame\n",
    "from camera import create_camera\n",
    "from prior import create_prior\n",
    "\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3918f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config with keys: 70\n",
      "Data folder: ./dataset_example/image_data/rp_dennis_posed_004\n",
      "Output folder: ./dataset_example/mesh_data/rp_dennis_posed_004/notebook\n"
     ]
    }
   ],
   "source": [
    "# Runtime paths (edit these as needed)\n",
    "CONFIG_PATH = 'cfg_files/fit_smpl.yaml'\n",
    "DATA_FOLDER = './dataset_example/image_data/rp_dennis_posed_004'\n",
    "OUTPUT_FOLDER = './dataset_example/mesh_data/rp_dennis_posed_004/notebook'\n",
    "\n",
    "# Parse the same config flow used by main.py\n",
    "sys.argv = [\n",
    "    'notebook',\n",
    "    '--config', CONFIG_PATH,\n",
    "    '--data_folder', DATA_FOLDER,\n",
    "    '--output_folder', OUTPUT_FOLDER,\n",
    "]\n",
    "\n",
    "args = parse_config()\n",
    "print('Loaded config with keys:', len(args))\n",
    "print('Data folder:', args['data_folder'])\n",
    "print('Output folder:', args['output_folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e47f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config saved to ./dataset_example/mesh_data/rp_dennis_posed_004/notebook/conf.yaml\n",
      "Views in dataset: 360\n",
      "Gender mode: neutral\n"
     ]
    }
   ],
   "source": [
    "# Step 1: output folder + dataset\n",
    "output_folder = args.pop('output_folder')\n",
    "output_folder = osp.expandvars(output_folder)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "conf_fn = osp.join(output_folder, 'conf.yaml')\n",
    "with open(conf_fn, 'w') as conf_file:\n",
    "    yaml.dump(args, conf_file)\n",
    "print(f'Config saved to {conf_fn}')\n",
    "\n",
    "float_dtype = args.get('float_dtype', 'float32')\n",
    "if float_dtype == 'float64':\n",
    "    dtype = torch.float64\n",
    "elif float_dtype == 'float32':\n",
    "    dtype = torch.float32\n",
    "else:\n",
    "    raise ValueError(f\"Unknown float type {float_dtype}\")\n",
    "\n",
    "use_cuda = args.get('use_cuda', True)\n",
    "if use_cuda and not torch.cuda.is_available():\n",
    "    raise RuntimeError('CUDA is not available. Set use_cuda=False in config or start a CUDA runtime.')\n",
    "\n",
    "img_folder = args.pop('img_folder', 'images')\n",
    "dataset_obj = create_dataset(img_folder=img_folder, **args)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "input_gender = args.pop('gender', 'neutral')\n",
    "gender_lbl_type = args.pop('gender_lbl_type', 'none')\n",
    "max_persons = args.pop('max_persons', -1)\n",
    "\n",
    "print('Views in dataset:', len(dataset_obj))\n",
    "print('Gender mode:', input_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "144926be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and priors initialized.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: body models + priors\n",
    "joint_mapper = JointMapper(dataset_obj.get_model2data())\n",
    "\n",
    "model_params = dict(\n",
    "    model_path=args.get('model_folder'),\n",
    "    joint_mapper=joint_mapper,\n",
    "    create_global_orient=True,\n",
    "    create_body_pose=not args.get('use_vposer'),\n",
    "    create_betas=True,\n",
    "    create_left_hand_pose=True,\n",
    "    create_right_hand_pose=True,\n",
    "    create_expression=True,\n",
    "    create_jaw_pose=True,\n",
    "    create_leye_pose=True,\n",
    "    create_reye_pose=True,\n",
    "    create_transl=False,\n",
    "    dtype=dtype,\n",
    "    **args,\n",
    ")\n",
    "\n",
    "male_model = smplx.create(gender='male', **model_params)\n",
    "neutral_model = None\n",
    "if args.get('model_type') != 'smplh':\n",
    "    neutral_model = smplx.create(gender='neutral', **model_params)\n",
    "female_model = smplx.create(gender='female', **model_params)\n",
    "\n",
    "use_hands = args.get('use_hands', True)\n",
    "use_face = args.get('use_face', True)\n",
    "\n",
    "body_pose_prior = create_prior(prior_type=args.get('body_prior_type'), dtype=dtype, **args)\n",
    "shape_prior = create_prior(prior_type=args.get('shape_prior_type', 'l2'), dtype=dtype, **args)\n",
    "angle_prior = create_prior(prior_type='angle', dtype=dtype)\n",
    "\n",
    "jaw_prior, expr_prior = None, None\n",
    "if use_face:\n",
    "    jaw_prior = create_prior(prior_type=args.get('jaw_prior_type'), dtype=dtype, **args)\n",
    "    expr_prior = create_prior(prior_type=args.get('expr_prior_type', 'l2'), dtype=dtype, **args)\n",
    "\n",
    "left_hand_prior, right_hand_prior = None, None\n",
    "if use_hands:\n",
    "    lhand_args = args.copy()\n",
    "    lhand_args['num_gaussians'] = args.get('num_pca_comps')\n",
    "    left_hand_prior = create_prior(prior_type=args.get('left_hand_prior_type'), dtype=dtype, use_left_hand=True, **lhand_args)\n",
    "\n",
    "    rhand_args = args.copy()\n",
    "    rhand_args['num_gaussians'] = args.get('num_pca_comps')\n",
    "    right_hand_prior = create_prior(prior_type=args.get('right_hand_prior_type'), dtype=dtype, use_right_hand=True, **rhand_args)\n",
    "\n",
    "print('Model and priors initialized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee6726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0000.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0018.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0036.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0054.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0072.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0090.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0108.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0126.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0144.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0162.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0180.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0198.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0216.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0234.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0252.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0270.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0288.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0306.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0324.jpg\n",
      "Processing: ./dataset_example/image_data/rp_dennis_posed_004/color/0342.jpg\n",
      "Selected views: 20\n"
     ]
    }
   ],
   "source": [
    "# Step 3: device transfer + multiview camera/keypoint assembly (use exactly 4 views)\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "female_model = female_model.to(device=device)\n",
    "male_model = male_model.to(device=device)\n",
    "if neutral_model is not None:\n",
    "    neutral_model = neutral_model.to(device=device)\n",
    "\n",
    "body_pose_prior = body_pose_prior.to(device=device)\n",
    "shape_prior = shape_prior.to(device=device)\n",
    "angle_prior = angle_prior.to(device=device)\n",
    "if use_face:\n",
    "    expr_prior = expr_prior.to(device=device)\n",
    "    jaw_prior = jaw_prior.to(device=device)\n",
    "if use_hands:\n",
    "    left_hand_prior = left_hand_prior.to(device=device)\n",
    "    right_hand_prior = right_hand_prior.to(device=device)\n",
    "\n",
    "joint_weights = dataset_obj.get_joint_weights().to(device=device, dtype=dtype)\n",
    "joint_weights.unsqueeze_(dim=0)\n",
    "\n",
    "img_list, keypoints_list, camera_list = [], [], []\n",
    "selected_image_ids = []\n",
    "\n",
    "view_num = len(dataset_obj)\n",
    "if view_num < 4:\n",
    "    raise ValueError(f'Need at least 4 images/views, but found {view_num}')\n",
    "\n",
    "selected_indices = np.linspace(0, view_num - 1, num=4, dtype=int).tolist()\n",
    "selected_indices = sorted(set(selected_indices))\n",
    "\n",
    "for idx in selected_indices:\n",
    "    data = dataset_obj[idx]\n",
    "\n",
    "    img = data['img']\n",
    "    keypoints = data['keypoints'][[0]]\n",
    "\n",
    "    focal_length = args.get('focal_length')\n",
    "    camera = create_camera(\n",
    "        focal_length_x=focal_length,\n",
    "        focal_length_y=focal_length,\n",
    "        dtype=dtype,\n",
    "        **args,\n",
    "    )\n",
    "\n",
    "    cam_R = data['cam_R']\n",
    "    cam_t = data['cam_t']\n",
    "    cam_fx = data['cam_fx']\n",
    "    cam_fy = data['cam_fy']\n",
    "    cam_cx = data['cam_cx']\n",
    "    cam_cy = data['cam_cy']\n",
    "\n",
    "    camera.focal_length_x = torch.full([1], cam_fx, dtype=dtype)\n",
    "    camera.focal_length_y = torch.full([1], cam_fy, dtype=dtype)\n",
    "    camera.center = torch.tensor([cam_cx, cam_cy], dtype=dtype).unsqueeze(0)\n",
    "    camera.rotation.data = torch.from_numpy(cam_R).unsqueeze(0)\n",
    "    camera.translation.data = torch.from_numpy(cam_t).unsqueeze(0)\n",
    "    camera.rotation.requires_grad = False\n",
    "    camera.translation.requires_grad = False\n",
    "\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        camera = camera.to(device)\n",
    "\n",
    "    img_list.append(img)\n",
    "    keypoints_list.append(keypoints)\n",
    "    camera_list.append(camera)\n",
    "    selected_image_ids.append(data['fn'])\n",
    "\n",
    "    print('Selected:', data['img_path'])\n",
    "\n",
    "print('Selected 4 image ids:', selected_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c85767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.1: visualize selected 4 views in a 2x2 grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (img, img_id) in enumerate(zip(img_list, selected_image_ids)):\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'Image ID: {img_id}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: run fitting and save outputs\n",
    "curr_result_fn = osp.join(output_folder, 'smpl_param.pkl')\n",
    "curr_mesh_fn = osp.join(output_folder, 'smpl_mesh.obj')\n",
    "\n",
    "gender = input_gender\n",
    "if gender == 'neutral':\n",
    "    if neutral_model is None:\n",
    "        raise RuntimeError('Neutral model is not available for model_type=smplh')\n",
    "    body_model = neutral_model\n",
    "elif gender == 'female':\n",
    "    body_model = female_model\n",
    "elif gender == 'male':\n",
    "    body_model = male_model\n",
    "else:\n",
    "    raise ValueError(f'Unknown gender: {gender}')\n",
    "\n",
    "fit_single_frame(\n",
    "    img_list,\n",
    "    keypoints_list,\n",
    "    body_model=body_model,\n",
    "    camera_list=camera_list,\n",
    "    joint_weights=joint_weights,\n",
    "    dtype=dtype,\n",
    "    output_folder=output_folder,\n",
    "    result_fn=curr_result_fn,\n",
    "    mesh_fn=curr_mesh_fn,\n",
    "    shape_prior=shape_prior,\n",
    "    expr_prior=expr_prior,\n",
    "    body_pose_prior=body_pose_prior,\n",
    "    left_hand_prior=left_hand_prior,\n",
    "    right_hand_prior=right_hand_prior,\n",
    "    jaw_prior=jaw_prior,\n",
    "    angle_prior=angle_prior,\n",
    "    **args,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print('Done. Result params:', curr_result_fn)\n",
    "print('Done. Result mesh:', curr_mesh_fn)\n",
    "print('Elapsed:', time.strftime('%Hh %Mm %Ss', time.gmtime(elapsed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2159b1d",
   "metadata": {},
   "source": [
    "## Next (planned)\n",
    "- Add image display cells for selected multiview inputs.\n",
    "- Project fitted mesh vertices to each image and render overlay for visual QA.\n",
    "- Save side-by-side overlay outputs under output folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiview-smplfy-x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
